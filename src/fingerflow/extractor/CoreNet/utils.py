import cv2
import numpy as np
import pandas as pd

from . import constants


def load_darknet_weights(model, weights_file_path):  # pylint: disable=too-many-locals
    conv_layer_size = 110
    conv_output_idxs = [93, 101, 109]
    with open(weights_file_path, 'rb') as weights_file:
        _, _, _, _, _ = np.fromfile(weights_file, dtype=np.int32, count=5)

        bn_idx = 0
        for conv_idx in range(conv_layer_size):
            conv_layer_name = f'conv2d_{conv_idx}' if conv_idx > 0 else 'conv2d'
            bn_layer_name = f'batch_normalization_{bn_idx}' if bn_idx > 0 else 'batch_normalization'

            conv_layer = model.get_layer(conv_layer_name)
            filters = conv_layer.filters
            kernel_size = conv_layer.kernel_size[0]
            # Get input dimensions from the layer's built state in Keras 3.x
            input_dims = conv_layer.kernel.shape[-2]  # Use kernel shape instead of input_shape

            if conv_idx not in conv_output_idxs:
                # darknet bn layer weights: [beta, gamma, mean, variance]
                bn_weights = np.fromfile(weights_file, dtype=np.float32, count=4 * filters)
                # tf bn layer weights: [gamma, beta, mean, variance]
                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]
                bn_layer = model.get_layer(bn_layer_name)
                bn_idx += 1
            else:
                conv_bias = np.fromfile(weights_file, dtype=np.float32, count=filters)

            # darknet shape: (out_dim, input_dims, height, width)
            # tf shape: (height, width, input_dims, out_dim)
            conv_shape = (filters, input_dims, kernel_size, kernel_size)
            conv_weights = np.fromfile(weights_file, dtype=np.float32, count=np.prod(conv_shape))
            conv_weights = conv_weights.reshape(conv_shape).transpose([2, 3, 1, 0])

            if conv_idx not in conv_output_idxs:
                conv_layer.set_weights([conv_weights])
                bn_layer.set_weights(bn_weights)
            else:
                conv_layer.set_weights([conv_weights, conv_bias])

        remaining_weights = len(weights_file.read())

        if remaining_weights == 0:
            print('all weights read')
        else:
            print(f'failed to read  all weights, # of unread weights: {remaining_weights}')


def preprocess_image_data(image_data):
    img = cv2.resize(image_data, constants.INPUT_SHAPE[:2])
    img = img / 255.

    imgs = np.expand_dims(img, axis=0)

    return imgs


def get_detection_data(img, model_outputs):
    num_bboxes = model_outputs[-1][0]
    boxes, scores, _ = [output[0][:num_bboxes] for output in model_outputs[:-1]]
    h, w = img.shape[:2]
    df = pd.DataFrame(boxes, columns=['x1', 'y1', 'x2', 'y2'])
    df[['x1', 'x2']] = (df[['x1', 'x2']] * w).astype('int64')
    df[['y1', 'y2']] = (df[['y1', 'y2']] * h).astype('int64')
    df['score'] = scores
    df['w'] = df['x2'] - df['x1']
    df['h'] = df['y2'] - df['y1']

    # print(f'# of bboxes: {num_bboxes}')

    return df
